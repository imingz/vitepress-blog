---
tags: [golang]
---

# 限流

限流是指在一段时间内，定义某个客户或应用可以接收或处理多少个请求的技术。例如，通过限流，你可以过滤掉产生流量峰值的客户和微服务，或者可以确保你的应用程序在自动扩展（Auto Scaling）失效前都不会出现过载的情况。

- 令牌桶、漏桶 针对单个节点，无法分布式限流。
- QPS 限流
  - 不同的请求可能需要数量迥异的资源来处理。
  - 某种静态 QPS 限流不是特别准。
- 给每个用户设置限制
  - 全局过载发生时候，针对某些“异常”进行控制。
  - 一定程度的“超卖”配额。
- 按照优先级丢弃。
- 拒绝请求也需要成本。

## 分布式限流

分布式限流，是为了控制某个应用全局的流量，而非真对单个节点纬度。

- 单个大流量的接口，使用 redis 容易产生热点。
- pre-request 模式对性能有一定影响，高频的网络往返。

![Alt text](images/4-%E9%99%90%E6%B5%81/image.png)

优化：从获取单个 quota 升级成批量 quota。quota: 表示速率，获取后使用令牌桶算法来限制。

- 每次心跳后，异步批量获取 quota，可以大大减少请求 redis 的频次，获取完以后本地消费，基于令牌桶拦截。
- 每次申请的配额需要手动设定静态值略欠灵活，比如每次要 20，还是 50。

![Alt text](images/4-%E9%99%90%E6%B5%81/image-1.png)

如何基于单个节点按需申请，并且避免出现不公平的现象？

- 初次使用默认值，一旦有过去历史窗口的数据，可以基于历史窗口数据进行 quota 请求。

优化：我们经常面临给一组用户划分稀有资源的问题，他们都享有等价的权利来获取资源，但是其中一些用户实际上只需要比其他用户少的资源。

### Max-Min Fairness

那么我们如何来分配资源呢？一种在实际中广泛使用的分享技术称作“最大最小公平分享”。

直观上，公平分享分配给每个用户想要的可以满足的最小需求，然后将没有使用的资源均匀的分配给需要‘大资源’的用户。

最大最小公平分配算法的形式化定义如下：

- 资源按照需求递增的顺序进行分配。
- 不存在用户得到的资源超过自己的需求。
- 未得到满足的用户等价的分享资源。

![Alt text](images/4-%E9%99%90%E6%B5%81/image-2.png)

## 限流对比

| 类型                   | 优点                                          | 缺点                                              | 现有实现         |
| ---------------------- | --------------------------------------------- | ------------------------------------------------- | ---------------- |
| 单机限制               | 1. 实现简单                                   | 1. 流量不均时会引起误限制                         | 非常多           |
|                        | 2. 稳定性高                                   | 2. 机器数变化时，需要手动调整，容易出错           |                  |
|                        | 3. 性能高                                     |                                                   |                  |
| 动态流控               | 1. 根据服务情况，动态限流                     | 1. 需要主动搜集请求的性能数据                     | BBR 限流         |
|                        | 2. 不需要调整额度                             | 2. 客户端主动善意限流                             | 广义上各种连接池 |
|                        |                                               | 3. 一般只用于接口调用，支持的范围小，应用场景狭小 |                  |
| 全局限流（分布式限流） | 1. 流量不均不会触发限流                       | 1. 实现复杂                                       | 无               |
|                        | 2. 机器数变动时无需调整                       | 2. 需要手动配置                                   |                  |
|                        | 3. 应用场景丰富，接口 DB 等任何资源都可以使用 |                                                   |                  |

## 重要性

每个接口配置阈值，运营工作繁重，最简单的我们配置服务级别 quota，更细粒度的，我们可以根据不同重要性设定 quota，我们引入了重要性（criticality）:

- 最重要 CRITICAL_PLUS，为最终的要求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。
- 重要 CRITICAL，生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题。但是可能没那么严重。
- 可丢弃的 SHEDABLE_PLUS 这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些请求通常可以过几分钟、几小时后重试。
- 可丢弃的 SHEDABLE 这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用。

gRPC 系统之间，需要自动传递重要性信息。如果后端接受到请求 A，在处理过程中发出了请求 B 和 C 给其他后端，请求 B 和 C 会使用与 A 相同的重要性属性。

- 全局配额不足时，优先拒绝低优先级的。
- 全局配额，可以按照重要性分别设置。
- 过载保护时，低优先级的请求先被拒绝。

## 熔断

断路器（Circuit Breakers）: 为了限制操作的持续时间，我们可以使用超时，超时可以防止挂起操作并保证系统可以响应。因为我们处于高度动态的环境中，几乎不可能确定在每种情况下都能正常工作的准确的时间限制。断路器以现实世界的电子元件命名，因为它们的行为是都是相同的。断路器在分布式系统中非常有用，因为重复的故障可能会导致雪球效应，并使整个系统崩溃。

- 服务依赖的资源出现大量错误。
- 某个用户超过资源配额时，后端任务会快速拒绝请求，返回“配额不足”的错误，但是拒绝回复仍然会消耗一定资源。有可能后端忙着不停发送拒绝请求，导致过载。

![Alt text](images/4-%E9%99%90%E6%B5%81/image-3.png)

::: info 参考公式 Google SRE
$max(0, (requests - K*accepts) / (requests + 1))$

- $requests$: 总请求数
- $accepts$: 成功请求数量
- $K$: 越大越激进

:::

## Gutter

基于熔断的 gutter kafka ，用于接管自动修复系统运行过程中的负载，这样只需要付出 10%的资源就能解决部分系统可用性问题。

我们经常使用 failover 的思路，但是完整的 failover 需要翻倍的机器资源，平常不接受流量时，资源浪费。高负载情况下接管流量又不一定完整能接住。所以这里核心利用熔断的思路，是把抛弃的流量转移到 gutter 集群，如果 gutter 也接受不住的流量，重新回抛到主集群，最大力度来接受。

![Alt text](images/4-%E9%99%90%E6%B5%81/image-4.png)

## 客户端流控

positive feedback: 用户总是积极重试，访问一个不可达的服务。

- 客户端需要限制请求频次，retry backoff 做一定的请求退让。
- 可以通过接口级别的 error_details，挂载到每个 API 返回的响应里。
